# Large Scale Data Scraping

## Introduction
Here are three files that scrape data about influencers from various global pages.<br>
For more details, see the Project Structure section.

## Project Strucutre
<b>1.University Staff Directory Scraper</b>

- <b>Script:</b>`10links.py`
- <b>Description:</b> This script scrapes data about staff from 10 university directory websites at the same time and saves the collected data to a CSV file
- <b>Columns and Data</b>
-- Name
-- Email 
-- Phone Number 
-- University Source URL

- <b>Output:</b> `staff_directory_data.csv`

<b>2.Unuversity data Scraper using AutoScraper</b>
- <b>Script:</b>
- <b>Description:</b>This script uses AutoScraper to extract staff data from a specific university name.
- <b>Columns and Data</b>
-- Name
-- Title
-- Email
-- Phone Number

<b>3.Faculty Directory Scraper</b>
- <b>Script:</b>`uni_autoscrape.py`
- <b>Description:</b>This script uses AutoScraper to extract staff data from a specific university name. 
- <b>Columns and Data:</b>
-- Name
-- Email
-- Department

- <b>Output:</b> `cornell_faculty.csv`


  # Getting started
  ## Usage
  <b>Clone the Repository</b>
  ```bash
  git clone https://github.com/AslanEmil008/Large-Scale-Data-Scraping.git
  cd
  ```
Then install requirments.txt
```bash
pip install -r requirements.txt
```
  
  


